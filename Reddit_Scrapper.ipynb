{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1438832,"sourceType":"datasetVersion","datasetId":843131}],"dockerImageVersionId":29994,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Reddit Scrapper Overview \nA walkthrough of the different features of the reddit scrapper package\n\nYou can read more about the process [here](https://towardsdatascience.com/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-on-heroku-part-1-574b69098d9a).","metadata":{}},{"cell_type":"code","source":"# Install the praw library \n!pip install praw","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:46:49.719506Z","iopub.execute_input":"2024-03-06T17:46:49.720416Z","iopub.status.idle":"2024-03-06T17:46:58.598944Z","shell.execute_reply.started":"2024-03-06T17:46:49.720303Z","shell.execute_reply":"2024-03-06T17:46:58.597908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install reddit_scraper","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:46:58.600930Z","iopub.execute_input":"2024-03-06T17:46:58.601197Z","iopub.status.idle":"2024-03-06T17:47:06.882591Z","shell.execute_reply.started":"2024-03-06T17:46:58.601163Z","shell.execute_reply":"2024-03-06T17:47:06.881763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the library\nimport reddit_scraper as rs\nimport praw\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:47:36.975766Z","iopub.execute_input":"2024-03-06T17:47:36.976068Z","iopub.status.idle":"2024-03-06T17:47:37.024879Z","shell.execute_reply.started":"2024-03-06T17:47:36.976040Z","shell.execute_reply":"2024-03-06T17:47:37.024243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Authenticating client","metadata":{}},{"cell_type":"code","source":"# Credentials generated from the reddit developers applications page\n# Hidden to protect my details. Add your own info.  \nmy_client_id = ''\nmy_client_secret = ''\nuser = ''","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:47:39.501562Z","iopub.execute_input":"2024-03-06T17:47:39.501837Z","iopub.status.idle":"2024-03-06T17:47:39.505339Z","shell.execute_reply.started":"2024-03-06T17:47:39.501808Z","shell.execute_reply":"2024-03-06T17:47:39.504783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reddit = praw.Reddit(client_id=my_client_id, client_secret=my_client_secret, user_agent=user)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:47:40.095825Z","iopub.execute_input":"2024-03-06T17:47:40.096114Z","iopub.status.idle":"2024-03-06T17:47:40.169667Z","shell.execute_reply.started":"2024-03-06T17:47:40.096075Z","shell.execute_reply":"2024-03-06T17:47:40.169095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of subreddits you want to scrape\nsubreddits = ['wearables', 'SmartWearables', 'Coros', 'Fittrack', 'WearableFitness', 'WearableDisplays']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts from multiple subreddits\nall_posts = []\n\nfor subreddit_name in subreddits:\n    subreddit = reddit.subreddit(subreddit_name)\n    posts = subreddit.new(limit=num_of_posts)  # You can use 'hot', 'new', 'rising', etc. instead of 'top'\n    \n    for post in posts:\n        all_posts.append({'Subreddit': subreddit_name, 'Title': post.title, 'Text': post.selftext, 'URL': post.url})\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Text', 'URL'])\n\n# Printing the DataFrame\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T05:53:59.886338Z","iopub.execute_input":"2024-03-06T05:53:59.887290Z","iopub.status.idle":"2024-03-06T05:54:22.272958Z","shell.execute_reply.started":"2024-03-06T05:53:59.887228Z","shell.execute_reply":"2024-03-06T05:54:22.272166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom datetime import datetime\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-03-06T05:55:26.128144Z","iopub.execute_input":"2024-03-06T05:55:26.128991Z","iopub.status.idle":"2024-03-06T05:55:26.132341Z","shell.execute_reply.started":"2024-03-06T05:55:26.128941Z","shell.execute_reply":"2024-03-06T05:55:26.131720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import praw\nimport pandas as pd\nfrom datetime import datetime\n\n# Assuming you have already initialized your Reddit instance as 'reddit'\n# reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n\n# List of subreddits you want to scrape\nsubreddits = ['wearables', 'SmartWearables', 'Coros', 'Fittrack', 'WearableFitness', 'WearableDisplays']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts from multiple subreddits\nall_posts = []\n\nfor subreddit_name in subreddits:\n    subreddit = reddit.subreddit(subreddit_name)\n    posts = subreddit.new(limit=num_of_posts)  # You can use 'hot', 'new', 'rising', etc. instead of 'top'\n    \n    for post in posts:\n        post_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n        all_posts.append({'Subreddit': subreddit_name, 'Title': post.title, 'Text': post.selftext, 'URL': post.url, 'Posted Date': post_date, 'Comments': post.num_comments})\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Text', 'URL', 'Posted Date', 'Comments'])\n\n# Printing the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T06:12:46.276468Z","iopub.execute_input":"2024-03-06T06:12:46.276800Z","iopub.status.idle":"2024-03-06T06:13:08.174554Z","shell.execute_reply.started":"2024-03-06T06:12:46.276767Z","shell.execute_reply":"2024-03-06T06:13:08.173836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming df is your DataFrame and 'XXX' is the column name\nfiltered_df = df[df['Text'].str.contains('wearable', case=False, na=False)]\n\n# Display the resulting DataFrame\nprint(filtered_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T06:15:44.686307Z","iopub.execute_input":"2024-03-06T06:15:44.686663Z","iopub.status.idle":"2024-03-06T06:15:44.706028Z","shell.execute_reply.started":"2024-03-06T06:15:44.686633Z","shell.execute_reply":"2024-03-06T06:15:44.705304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"['wearables', 'SmartWearables', 'Coros', 'Fittrack', 'WearableFitness', 'WearableDisplays',]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import praw\nimport pandas as pd\nfrom datetime import datetime\n\n# Assuming you have already initialized your Reddit instance as 'reddit'\n# reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n\n# List of subreddits you want to scrape\nsubreddits = ['WearableDisplays']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts from multiple subreddits\nall_posts = []\n\nfor subreddit_name in subreddits:\n    subreddit = reddit.subreddit(subreddit_name)\n    posts = subreddit.new(limit=num_of_posts)  # You can use 'hot', 'new', 'rising', etc. instead of 'top'\n    \n    for post in posts:\n        post_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n        all_posts.append({'Subreddit': subreddit_name, 'Title': post.title, 'Text': post.selftext, 'URL': post.url, 'Posted Date': post_date, 'Comments': post.num_comments})\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Text', 'URL', 'Posted Date', 'Comments'])\n\n# Printing the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T06:19:14.802054Z","iopub.execute_input":"2024-03-06T06:19:14.802610Z","iopub.status.idle":"2024-03-06T06:19:15.202696Z","shell.execute_reply.started":"2024-03-06T06:19:14.802577Z","shell.execute_reply":"2024-03-06T06:19:15.202131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming df is your DataFrame and 'XXX' is the column name\nfiltered_df = df[df['Text'].str.contains('wearable', case=False, na=False)]\n\n# Display the resulting DataFrame\nprint(filtered_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T06:18:18.156583Z","iopub.execute_input":"2024-03-06T06:18:18.157225Z","iopub.status.idle":"2024-03-06T06:18:18.171949Z","shell.execute_reply.started":"2024-03-06T06:18:18.157190Z","shell.execute_reply":"2024-03-06T06:18:18.171389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import praw\nimport pandas as pd\nfrom datetime import datetime\n\n# Assuming you have already initialized your Reddit instance as 'reddit'\n# reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n\n# Words to filter posts and comments\nfilter_words = ['health wearables']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts from the entire Reddit site\nall_posts = []\n\n# Using Reddit's search to find posts containing the specified filter words\nresults = reddit.subreddit('all').search(' OR '.join(filter_words), sort='new', limit=num_of_posts)\n\nfor post in results:\n    post_date = datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n    \n    all_posts.append({'Subreddit': post.subreddit.display_name, 'Title': post.title, 'Text': post.selftext, 'URL': post.url, 'Posted Date': post_date, 'Comments': post.num_comments})\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Text', 'URL', 'Posted Date', 'Comments'])\n\n# Printing the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:48:26.959757Z","iopub.execute_input":"2024-03-06T17:48:26.959996Z","iopub.status.idle":"2024-03-06T17:48:31.202018Z","shell.execute_reply.started":"2024-03-06T17:48:26.959971Z","shell.execute_reply":"2024-03-06T17:48:31.201346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import praw\nimport pandas as pd\nfrom datetime import datetime\n\n# Assuming you have already initialized your Reddit instance as 'reddit'\n# reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n\n# Words to filter posts and comments\nfilter_words = ['health wearables']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts and comments from the entire Reddit site\nall_posts = []\n\n# Using Reddit's search to find posts containing the specified filter words\nresults = reddit.subreddit('all').search(' OR '.join(filter_words), sort='new', limit=num_of_posts)\n\nfor submission in results:\n    post_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n    \n    all_posts.append({'Subreddit': submission.subreddit.display_name, 'Title': submission.title, 'Post_Text': submission.selftext, 'URL': submission.url, 'Posted Date': post_date, 'Comments': submission.num_comments})\n    \n    # Adding comments to the list\n    submission.comments.replace_more(limit=None)\n    for comment in submission.comments.list():\n        comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n        all_posts.append({'Subreddit': submission.subreddit.display_name, 'Title': submission.title, 'Comment_Text': comment.body, 'URL': submission.url, 'Posted Date': comment_date, 'Comments': 0})\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Post_Text', 'Comment_Text', 'URL', 'Posted Date', 'Comments'])\n\n# Printing the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:18:48.307238Z","iopub.execute_input":"2024-03-06T18:18:48.307904Z","iopub.status.idle":"2024-03-06T18:19:34.935948Z","shell.execute_reply.started":"2024-03-06T18:18:48.307870Z","shell.execute_reply":"2024-03-06T18:19:34.935438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:30:27.704614Z","iopub.execute_input":"2024-03-06T18:30:27.705184Z","iopub.status.idle":"2024-03-06T18:30:27.718734Z","shell.execute_reply.started":"2024-03-06T18:30:27.705152Z","shell.execute_reply":"2024-03-06T18:30:27.718143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exporting the DataFrame to a CSV file\ndf.to_csv('reddit_final_data.csv', index=False)\n\n# Printing a message indicating successful export\nprint(\"DataFrame has been exported to 'reddit_data.csv'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:19:34.942338Z","iopub.execute_input":"2024-03-06T18:19:34.942493Z","iopub.status.idle":"2024-03-06T18:19:35.001018Z","shell.execute_reply.started":"2024-03-06T18:19:34.942473Z","shell.execute_reply":"2024-03-06T18:19:35.000552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import praw\nimport pandas as pd\nfrom datetime import datetime\n\n# Assuming you have already initialized your Reddit instance as 'reddit'\n# reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n\n# Words to filter posts and comments\nfilter_words = filter_words = ['health wearables', 'health sensors', 'healthcare wearable', 'healthcare sensors']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts and comments from the entire Reddit site\nall_posts = []\n\n# Using Reddit's search to find posts containing the specified filter words\nresults = reddit.subreddit('all').search(' OR '.join(filter_words), sort='new', limit=num_of_posts)\n\nfor submission in results:\n    post_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n    \n    all_posts.append({'Subreddit': submission.subreddit.display_name, 'Title': submission.title, 'Post_Text': submission.selftext, 'URL': submission.url, 'Posted Date': post_date, 'Comments': submission.num_comments})\n    \n    # Adding comments to the list\n    submission.comments.replace_more(limit=None)\n    for comment in submission.comments.list():\n        comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n        all_posts.append({'Subreddit': submission.subreddit.display_name, 'Title': submission.title, 'Comment_Text': comment.body, 'URL': submission.url, 'Posted Date': comment_date, 'Comments': 0})\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Post_Text', 'Comment_Text', 'URL', 'Posted Date', 'Comments'])\n\n# Printing the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:26:21.378656Z","iopub.execute_input":"2024-03-06T18:26:21.378939Z","iopub.status.idle":"2024-03-06T18:27:05.549859Z","shell.execute_reply.started":"2024-03-06T18:26:21.378912Z","shell.execute_reply":"2024-03-06T18:27:05.549275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exporting the DataFrame to a CSV file\ndf.to_csv('multi_words_reddit_scrape.csv', index=False)\n\n# Printing a message indicating successful export\nprint(\"DataFrame has been exported to 'reddit_data.csv'\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:27:05.551068Z","iopub.execute_input":"2024-03-06T18:27:05.551335Z","iopub.status.idle":"2024-03-06T18:27:05.625812Z","shell.execute_reply.started":"2024-03-06T18:27:05.551310Z","shell.execute_reply":"2024-03-06T18:27:05.625321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:27:05.626674Z","iopub.execute_input":"2024-03-06T18:27:05.626847Z","iopub.status.idle":"2024-03-06T18:27:05.631177Z","shell.execute_reply.started":"2024-03-06T18:27:05.626827Z","shell.execute_reply":"2024-03-06T18:27:05.630650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import praw\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n# Assuming you have already initialized your Reddit instance as 'reddit'\n# reddit = praw.Reddit(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET', user_agent='YOUR_USER_AGENT')\n\n# Words to filter posts and comments\nfilter_words = ['health wearables']\n\n# Number of posts you want in your data\nnum_of_posts = 100000\n\n# Collecting posts and comments from the entire Reddit site\nall_posts = []\n\n# Specify the time range for the search (e.g., fetch posts from the last 10 years)\nend_date = datetime.utcnow()\nstart_date = end_date - timedelta(days=3652)  # Roughly 10 years\n\n# Fetching posts in chunks based on specified time periods\nwhile start_date < end_date:\n    # Using Reddit's search to find posts containing the specified filter words\n    results = reddit.subreddit('all').search(f'{\",\".join(filter_words)} timestamp:{int(start_date.timestamp())}..{int(end_date.timestamp())}', sort='new', limit=num_of_posts)\n\n    for submission in results:\n        post_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n\n        all_posts.append({'Subreddit': submission.subreddit.display_name, 'Title': submission.title, 'Post_Text': submission.selftext, 'URL': submission.url, 'Posted Date': post_date, 'Comments': submission.num_comments})\n\n        # Adding comments to the list\n        submission.comments.replace_more(limit=None)\n        for comment in submission.comments.list():\n            comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n            all_posts.append({'Subreddit': submission.subreddit.display_name, 'Title': submission.title, 'Comment_Text': comment.body, 'URL': submission.url, 'Posted Date': comment_date, 'Comments': 0})\n\n    # Update the time range for the next request\n    end_date = start_date\n    start_date = end_date - timedelta(days=3652)  # Another 10 years back\n\n# Creating a Pandas DataFrame with specific column names\ndf = pd.DataFrame(all_posts, columns=['Subreddit', 'Title', 'Post_Text', 'Comment_Text', 'URL', 'Posted Date', 'Comments'])\n\n# Printing the DataFrame\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T19:13:19.647295Z","iopub.execute_input":"2024-03-06T19:13:19.647528Z","iopub.status.idle":"2024-03-06T19:13:19.731209Z","shell.execute_reply.started":"2024-03-06T19:13:19.647464Z","shell.execute_reply":"2024-03-06T19:13:19.730429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exporting the DataFrame to a CSV file\ndf.to_csv('10_years_reddit.csv', index=False)\n\n# Printing a message indicating successful export\nprint(\"DataFrame has been exported to 'reddit_data.csv'\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T19:13:19.731677Z","iopub.status.idle":"2024-03-06T19:13:19.731940Z","shell.execute_reply.started":"2024-03-06T19:13:19.731818Z","shell.execute_reply":"2024-03-06T19:13:19.731832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-06T19:13:19.732916Z","iopub.status.idle":"2024-03-06T19:13:19.733154Z","shell.execute_reply.started":"2024-03-06T19:13:19.733036Z","shell.execute_reply":"2024-03-06T19:13:19.733049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}